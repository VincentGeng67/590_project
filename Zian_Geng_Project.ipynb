{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T05:44:07.338707Z",
     "start_time": "2020-11-17T05:44:05.704549Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import models\n",
    "from utils import progress_bar\n",
    "from train import myModel\n",
    "from cutout import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T05:44:08.397159Z",
     "start_time": "2020-11-17T05:44:07.341011Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutout=False\n",
    "batch_size=128\n",
    "length=16\n",
    "\n",
    "\n",
    "if cutout:\n",
    "    \n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "    transform_train.transforms.append(Cutout(n_holes=1, length=length))\n",
    "else:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='~/data', train=True, download=False,\n",
    "                            transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = datasets.CIFAR10(root='~/data', train=False, download=False,\n",
    "                           transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T05:48:48.847871Z",
     "start_time": "2020-11-17T05:44:08.399425Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "==> Building model..\n5\nUsing CUDA..\nstart at  0\nbest =  0\n\nEpoch: 0\nEpoch 0 Train acc 16.341999 percent \nSaving..\nEpoch 0 Test acc 21.440001 percent \n0.01\n\nEpoch: 1\nEpoch 1 Train acc 24.954000 percent \nSaving..\nEpoch 1 Test acc 26.309999 percent \n\nEpoch: 2\nEpoch 2 Train acc 28.172001 percent \nSaving..\nEpoch 2 Test acc 29.600000 percent \n\nEpoch: 3\nEpoch 3 Train acc 30.910000 percent \nSaving..\nEpoch 3 Test acc 34.770000 percent \n\nEpoch: 4\nEpoch 4 Train acc 33.924000 percent \nSaving..\nEpoch 4 Test acc 37.020000 percent \n\nEpoch: 5\nEpoch 5 Train acc 36.686001 percent \nSaving..\nEpoch 5 Test acc 39.790001 percent \n\nEpoch: 6\nEpoch 6 Train acc 39.824001 percent \nEpoch 6 Test acc 39.139999 percent \n\nEpoch: 7\nEpoch 7 Train acc 41.161999 percent \nSaving..\nEpoch 7 Test acc 42.610001 percent \n\nEpoch: 8\nEpoch 8 Train acc 43.220001 percent \nSaving..\nEpoch 8 Test acc 43.070000 percent \n\nEpoch: 9\nEpoch 9 Train acc 45.453999 percent \nSaving..\nEpoch 9 Test acc 46.020000 percent \n\nEpoch: 10\nEpoch 10 Train acc 47.439999 percent \nSaving..\nEpoch 10 Test acc 48.189999 percent \n\nEpoch: 11\nEpoch 11 Train acc 48.700001 percent \nSaving..\nEpoch 11 Test acc 49.910000 percent \n\nEpoch: 12\nEpoch 12 Train acc 50.826000 percent \nSaving..\nEpoch 12 Test acc 50.950001 percent \n\nEpoch: 13\nEpoch 13 Train acc 52.290001 percent \nSaving..\nEpoch 13 Test acc 53.689999 percent \n\nEpoch: 14\nEpoch 14 Train acc 54.062000 percent \nSaving..\nEpoch 14 Test acc 56.209999 percent \n\nEpoch: 15\nEpoch 15 Train acc 56.208000 percent \nSaving..\nEpoch 15 Test acc 57.389999 percent \n\nEpoch: 16\nEpoch 16 Train acc 58.084000 percent \nSaving..\nEpoch 16 Test acc 59.160000 percent \n\nEpoch: 17\nEpoch 17 Train acc 59.826000 percent \nSaving..\nEpoch 17 Test acc 60.029999 percent \n\nEpoch: 18\nEpoch 18 Train acc 61.183998 percent \nSaving..\nEpoch 18 Test acc 64.209999 percent \n\nEpoch: 19\nEpoch 19 Train acc 62.756001 percent \nEpoch 19 Test acc 63.290001 percent \n\nEpoch: 20\nEpoch 20 Train acc 63.798000 percent \nSaving..\nEpoch 20 Test acc 64.339996 percent \n\nEpoch: 21\nEpoch 21 Train acc 65.248001 percent \nSaving..\nEpoch 21 Test acc 66.129997 percent \n\nEpoch: 22\nEpoch 22 Train acc 66.417999 percent \nSaving..\nEpoch 22 Test acc 66.610001 percent \n\nEpoch: 23\nEpoch 23 Train acc 67.419998 percent \nSaving..\nEpoch 23 Test acc 68.430000 percent \n\nEpoch: 24\nEpoch 24 Train acc 68.561996 percent \nSaving..\nEpoch 24 Test acc 69.599998 percent \n\nEpoch: 25\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3fe1df4a7086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmixup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d Train acc %f percent \"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtr_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/590_project/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch, trainloader, mixup, alpha, cutoff)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_list=[\"ResNet18\",\"ResNet34\",\"ResNet50\"]\n",
    "name_list=[\"ResNet18_alpha=1\",\"ResNet34_alpha=1\",\"ResNet50_alpha=1\"]\n",
    "Tr_acclist_alpha=[]\n",
    "Te_acclist_alpha=[]\n",
    "\n",
    "for i in range(3):\n",
    "    sname=name_list[i]\n",
    "    mod=model_list[i]\n",
    "    resnet=myModel(mod,sname,con=False)\n",
    "    print(\"start at \",resnet.start_epoch)\n",
    "    print(\"best = \",resnet.best_acc)\n",
    "    tr_acc=[]\n",
    "    te_acc=[]\n",
    "\n",
    "    if not os.path.exists(resnet.logname):\n",
    "        with open(resnet.logname, 'w') as logfile:\n",
    "            logwriter = csv.writer(logfile, delimiter=',')\n",
    "            logwriter.writerow(['epoch', 'train loss', 'reg loss', 'train acc',\n",
    "                            'test loss', 'test acc'])    \n",
    "    \n",
    "    for epoch in range(resnet.start_epoch, 100):\n",
    "        train_loss, reg_loss, train_acc = resnet.train(epoch,trainloader,mixup=True,alpha=1.)\n",
    "        print(\"Epoch %d Train acc %f percent \"%(epoch,train_acc))\n",
    "        tr_acc.append(train_acc)\n",
    "        test_loss, test_acc = resnet.test(epoch,testloader)\n",
    "        print(\"Epoch %d Test acc %f percent \"%(epoch,test_acc))\n",
    "        te_acc.append(test_acc)\n",
    "        resnet.adjust_learning_rate(resnet.optimizer, epoch)\n",
    "        with open(resnet.logname, 'a') as logfile:\n",
    "            logwriter = csv.writer(logfile, delimiter=',')\n",
    "            logwriter.writerow([epoch, train_loss, reg_loss, float(train_acc.data), test_loss,\n",
    "                            float(test_acc.data)])\n",
    "    print(\"best = \",resnet.best_acc)\n",
    "    train=[]\n",
    "    test=[]\n",
    "    for i in range(len(tr_acc)):\n",
    "        train.append(float(tr_acc[i].data))\n",
    "        test.append(float(te_acc[i].data))\n",
    "    print(sname+\" train\")\n",
    "    print(train)\n",
    "    print(sname+\" test\")\n",
    "    print(test)\n",
    "    Tr_acclist_alpha.append(train)\n",
    "    Te_acclist_alpha.append(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "best =  tensor(87.9000)\n"
    }
   ],
   "source": [
    "print(\"best = \",resnet.best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Cutout' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fdcebef9646b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                              (0.2023, 0.1994, 0.2010)),\n\u001b[1;32m     14\u001b[0m             ])\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtransform_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCutout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_holes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     transform_train = transforms.Compose([\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Cutout' is not defined"
     ]
    }
   ],
   "source": [
    "cutout=True\n",
    "batch_size=128\n",
    "length=16\n",
    "\n",
    "\n",
    "if cutout:\n",
    "    \n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "    transform_train.transforms.append(Cutout(n_holes=1, length=length))\n",
    "else:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='~/data', train=True, download=False,\n",
    "                            transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = datasets.CIFAR10(root='~/data', train=False, download=False,\n",
    "                           transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "\n",
    "model_list=[\"ResNet18\",\"ResNet34\",\"ResNet50\"]\n",
    "name_list=[\"ResNet18_length=16\",\"ResNet34_length=16\",\"ResNet50_length=16\"]\n",
    "Tr_acclist_length=[]\n",
    "Te_acclist_length=[]\n",
    "\n",
    "for i in range(3):\n",
    "    sname=name_list[i]\n",
    "    mod=model_list[i]\n",
    "    resnet=myModel(mod,sname,con=False)\n",
    "    print(\"start at \",resnet.start_epoch)\n",
    "    print(\"best = \",resnet.best_acc)\n",
    "    tr_acc=[]\n",
    "    te_acc=[]\n",
    "\n",
    "    if not os.path.exists(resnet.logname):\n",
    "        with open(resnet.logname, 'w') as logfile:\n",
    "            logwriter = csv.writer(logfile, delimiter=',')\n",
    "            logwriter.writerow(['epoch', 'train loss', 'reg loss', 'train acc',\n",
    "                            'test loss', 'test acc'])    \n",
    "    \n",
    "    for epoch in range(resnet.start_epoch, 100):\n",
    "        train_loss, reg_loss, train_acc = resnet.train(epoch,trainloader,mixup=False)\n",
    "        print(\"Epoch %d Train acc %f percent \"%(epoch,train_acc))\n",
    "        tr_acc.append(train_acc)\n",
    "        test_loss, test_acc = resnet.test(epoch,testloader)\n",
    "        print(\"Epoch %d Test acc %f percent \"%(epoch,test_acc))\n",
    "        te_acc.append(test_acc)\n",
    "        resnet.adjust_learning_rate(resnet.optimizer, epoch)\n",
    "        with open(resnet.logname, 'a') as logfile:\n",
    "            logwriter = csv.writer(logfile, delimiter=',')\n",
    "            logwriter.writerow([epoch, train_loss, reg_loss, float(train_acc.data), test_loss,\n",
    "                            float(test_acc.data)])\n",
    "    print(\"best = \",resnet.best_acc)\n",
    "    train=[]\n",
    "    test=[]\n",
    "    for i in range(len(tr_acc)):\n",
    "        train.append(float(tr_acc[i].data))\n",
    "        test.append(float(te_acc[i].data))\n",
    "    print(sname+\" train\")\n",
    "    print(train)\n",
    "    print(sname+\" test\")\n",
    "    print(test)\n",
    "    Tr_acclist_length.append(train)\n",
    "    Te_acclist_length.append(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.12-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}